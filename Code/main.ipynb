{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to refactor pre-existing code to make it generalizable to any dataset.\n",
    "\n",
    "*(c) Amir Reza Vazifeh and Jatearoon (Keene) Boondicharern*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import earthpy.plot as ep\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.signal import wiener\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_data(parent, image = [\"PaviaU\"]):\n",
    "    \"\"\"\n",
    "    Loads simple PaviaU and Salinas (currently misformatted) data from mat file.\n",
    "    \"\"\"\n",
    "    for p in image:\n",
    "        x = loadmat(os.path.join(parent, p, p) + \".mat\")\n",
    "        x = x[p[0].lower() + p[1:]]\n",
    "        y = loadmat(os.path.join(parent, p, p) + \"_gt.mat\")\n",
    "        y = y[p[0].lower() + p[1:] + '_gt']\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, gt = load_simple_data(\"/home/bigkeenus/Desktop/JASON/Datasets/\")\n",
    "print(f\"Data Shape: {data.shape[:-1]}\\nNumber of Bands: {data.shape[-1]}\")\n",
    "# ep.plot_bands(gt, cmap='nipy_spectral', title='Ground Truth of PaviaU', figsize=(10, 8))\n",
    "plt.show()\n",
    "plt.imshow(data[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, a=2, b=-1, h = 1/1024):\n",
    "    \"\"\"\n",
    "    Normalizes image to the range of [0, 1].\n",
    "\n",
    "    Given a final image X, adjust normalization range by performing:\n",
    "\n",
    "    a * X + b\n",
    "    \"\"\"\n",
    "    # Normalize the image to [0, 1]\n",
    "    min_val = image.min()\n",
    "    max_val = image.max()\n",
    "    image_normalized = (image - min_val) / (max_val - min_val + h)\n",
    "\n",
    "    # Scale to [-1, 1]\n",
    "    image_scaled = a * image_normalized + b\n",
    "    return image_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperspectral_video(image, video_name, colormap='jet', fps=10):\n",
    "    \"\"\"\n",
    "    Create a video from a hyperspectral image with a fixed colorbar.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Hyperspectral image (Height x Width x Bands).\n",
    "    - video_name: Name of the output video file.\n",
    "    - colormap: Colormap to apply (default: 'jet').\n",
    "    - fps: Frames per second for the video (default: 10).\n",
    "    \"\"\"\n",
    "    height, width, bands = image.shape\n",
    "    temp_dir = \"frames_temp\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=0.05, right=1.00, top=0.95, bottom=0.05)\n",
    "    # colorbar_ax = fig.add_axes([0.75, 0.2, 0.03, 0.6])  # Adjusted colorbar position\n",
    "\n",
    "    # Save each frame\n",
    "    frame_paths = []\n",
    "    for band in range(bands):\n",
    "        ax.clear()\n",
    "        band_data = image[:, :, band]\n",
    "        im = ax.imshow(band_data, cmap=colormap, vmin=np.min(image), vmax=np.max(image))\n",
    "        ax.set_title(f\"Band {band + 1}\", fontsize=14)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Add a fixed colorbar\n",
    "        if band == 0:  # Only add colorbar for the first frame\n",
    "            # colorbar = fig.colorbar(im, cax=colorbar_ax)\n",
    "            colorbar = fig.colorbar(im)\n",
    "            colorbar.set_label('Intensity', fontsize=12)\n",
    "\n",
    "        # Save frame as an image\n",
    "        frame_path = os.path.join(temp_dir, f\"frame_{band:03d}.png\")\n",
    "        plt.savefig(frame_path, dpi=200, bbox_inches='tight')\n",
    "        frame_paths.append(frame_path)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Compile the frames into a video\n",
    "    first_frame = cv2.imread(frame_paths[0])\n",
    "    video_height, video_width, _ = first_frame.shape\n",
    "    video_writer = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (video_width, video_height))\n",
    "\n",
    "    for frame_path in frame_paths:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    video_writer.release()\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for frame_path in frame_paths:\n",
    "        os.remove(frame_path)\n",
    "    os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Implicit Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(w, h, dim=2, low=-1, hi=1):\n",
    "    \"\"\"\n",
    "    creates a dim-dimensional meshgrid of size (w, h) values ranging from [low, hi]\n",
    "    \"\"\"\n",
    "    # Create the coordinate grid for x and y dimensions\n",
    "    x_coords = torch.linspace(low, hi, steps=w)\n",
    "    y_coords = torch.linspace(low, hi, steps=h)\n",
    "\n",
    "    # Generate the meshgrid for coordinates\n",
    "    grid = torch.meshgrid(x_coords, y_coords)\n",
    "\n",
    "    # Stack the meshgrid and reshape to match the required flattened shape\n",
    "    mgrid = torch.stack(grid, dim=-1).reshape(-1, dim)\n",
    "\n",
    "    return mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All SIREN code has been moved into another class\n",
    "from siren import SineLayer, Siren\n",
    "from PosEnc import PosEncMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combined Dataset class for both grayscale and RGB images\n",
    "class ImageFittingWithMask(Dataset):\n",
    "    def __init__(self, img_tensor, mask_ratio=0.6, mask=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_shape = img_tensor.shape[1:]\n",
    "        num_channels = img_tensor.shape[0]\n",
    "        self.pixels = img_tensor.permute(1, 2, 0).reshape(-1, num_channels)  # Handle grayscale (1 channel) or RGB (3 channels)\n",
    "        self.coords = make_grid(self.img_shape[0], self.img_shape[1], 2)\n",
    "\n",
    "        # If a mask is provided, use it, otherwise generate a random mask\n",
    "        if mask is not None:\n",
    "            mask = cv2.resize(mask, (self.img_shape[1], self.img_shape[0]))\n",
    "            mask = torch.tensor(mask, dtype=torch.bool).view(-1)\n",
    "        else:\n",
    "            num_pixels = self.pixels.shape[0]\n",
    "            random_mask = torch.randperm(num_pixels)[:int(num_pixels * (1 - mask_ratio))]\n",
    "            mask = torch.zeros(num_pixels, dtype=torch.bool)\n",
    "            mask[random_mask] = True\n",
    "\n",
    "        self.mask = mask\n",
    "\n",
    "        # Apply the mask to training data\n",
    "        self.visible_coords = self.coords[self.mask]\n",
    "        self.visible_pixels = self.pixels[self.mask]\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > 0:\n",
    "            raise IndexError\n",
    "        return self.visible_coords, self.visible_pixels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make a Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperspectral_masks(height=610, width=340, bands=103, num_masks=10, mask_size_ratio=0.1):\n",
    "    if (isinstance(num_masks, int)):\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        selected_bands = np.random.choice(bands, num_masks, replace=False)\n",
    "    else:\n",
    "        selected_bands = num_masks\n",
    "        num_masks = selected_bands.shape[0] # channel dimension\n",
    "    # make the grid\n",
    "    W = np.linspace(0, width, width, endpoint=False, dtype=int)\n",
    "    H = np.linspace(0, height, height, endpoint=False, dtype=int)\n",
    "    coords = np.meshgrid(W, H)\n",
    "    coords = np.stack(coords, axis=-1).reshape(-1, 2) # form a list of coordinates\n",
    "    np.random.shuffle(coords) # randomly shuffle coordinates\n",
    "    \n",
    "    masks = {}\n",
    "    groupings = None\n",
    "    if (1/num_masks == mask_size_ratio):\n",
    "        # assuming that it is an even split\n",
    "        groupings = np.array_split(coords, num_masks)\n",
    "        for idx, b in enumerate(selected_bands):\n",
    "            masks[b] = list(groupings[idx])\n",
    "    else:\n",
    "        print(f\"WARNING: number of masks {num_masks} is not the same as the mask size ratio {mask_size_ratio}\")\n",
    "        pixels_per_band = int(mask_size_ratio * height*width)\n",
    "        # the split is not perfect so randomly select groups that will overlap in some way shape or form\n",
    "        coords_index = np.array(list(range(coords.shape[0])))\n",
    "        for b in selected_bands:\n",
    "            choice = np.random.choice(coords_index, pixels_per_band)\n",
    "            masks[b] = list(coords[choice]) \n",
    "    return masks\n",
    "\n",
    "# Generate masks\n",
    "h, w, c = np.shape(data)\n",
    "hyperspectral_masks = generate_hyperspectral_masks(height=h, width=w, bands=c, num_masks=10, mask_size_ratio=0.1)\n",
    "\n",
    "# Example: Print masks for the first selected band\n",
    "print(f\"There are {len(hyperspectral_masks.keys())}:\")\n",
    "for i, mask in enumerate(hyperspectral_masks.values()):\n",
    "    print(f\"Mask {i+1}: {mask[:5]} ... {len(mask)} pixels\")  # Print first 5 coordinates for preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_masks(masks, height=610, width=340, vis = False):\n",
    "    band_masks = list(masks.values())\n",
    "    num_masks = len(band_masks)\n",
    "    num_rows = (num_masks + 4) // 5  # Ensure 5 images per row\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 5, figsize=(35, 10 * num_rows))\n",
    "\n",
    "    # If there's only one row, axes will not be a 2D array\n",
    "    if num_rows == 1 and vis:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    if (not vis):\n",
    "        plt.close(fig)\n",
    "    all_masks = []\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_masks:\n",
    "            mask_img = np.zeros((height, width), dtype=np.uint8)\n",
    "            for x, y in band_masks[i]:\n",
    "                mask_img[y, x] = 1\n",
    "            if (vis):\n",
    "                ax.imshow(mask_img, cmap='gray')\n",
    "                ax.set_title(f'Mask {i+1}', fontsize=24)\n",
    "            all_masks.append(mask_img)\n",
    "        else:\n",
    "            if (vis):\n",
    "                ax.axis('off')  # Hide unused subplots\n",
    "    if (vis):\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "    return all_masks\n",
    "\n",
    "# Visualize masks\n",
    "all_masks = visualize_masks(hyperspectral_masks, height=h, width=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_matrix_sum = np.zeros_like(all_masks[0])\n",
    "for m in all_masks:\n",
    "    running_matrix_sum += m\n",
    "print(f\"sum of elements - matrix size (should be 0): {running_matrix_sum.sum() - running_matrix_sum.shape[0]*running_matrix_sum.shape[1]}, max: {running_matrix_sum.max()} min: {running_matrix_sum.min()}\")\n",
    "# plt.imshow(running_matrix_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Generalized Training Methods\n",
    "\n",
    "In this section, a generalized data loading and hyperspectral data loader should be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim1\n",
    "\n",
    "def mseloss(X, Y):\n",
    "    return ((X - Y) ** 2).mean()\n",
    "def psnr(X, Y):\n",
    "    return 10 * np.log10(np.max(Y)**2 / mseloss(X, Y))\n",
    "def ssim(X, Y, multichannel=True):\n",
    "    if (multichannel):\n",
    "        return np.mean([ssim1(Y[:, :, i], X[:, :, i], data_range=2) for i in range(X.shape[-1])])\n",
    "    return ssim1(X, Y, data_range=1, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(X, Y):\n",
    "    return mseloss(X, Y), psnr(X, Y), ssim(X, Y)\n",
    "    \n",
    "def fit_image(hsi, masks, train_steps=2501, siren_model=None, lr = 1e-4):\n",
    "    \"\"\"\n",
    "    Given pre-selected normalized hyperspectral image bands with dimension (H, W, C)\n",
    "    As well as the masks perform reconstruction\n",
    "    \"\"\"\n",
    "    width, height = hsi.shape[1], hsi.shape[-1]\n",
    "\n",
    "    mses, psnrs, ssims = ([], [], [])\n",
    "    reconstructed, gt = ([], [])\n",
    "    for idx, HSI in enumerate(hsi):\n",
    "        channel = HSI\n",
    "        channel_tensor = torch.from_numpy(channel).float()\n",
    "        channel_tensor = channel_tensor.unsqueeze(0)\n",
    "        \n",
    "        target_image = ImageFittingWithMask(\n",
    "            img_tensor=channel_tensor,\n",
    "            mask_ratio=0.9, # irrelevant since we provide the masks\n",
    "            mask=masks[idx, :, :])\n",
    "        dataloader = DataLoader(target_image, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "        if (siren_model is None):\n",
    "            siren = Siren(\n",
    "                in_features=2,\n",
    "                out_features=channel_tensor.size()[0],\n",
    "                hidden_features=256,\n",
    "                hidden_layers=3,\n",
    "                outermost_linear=True,\n",
    "                activation=\"SINE\")\n",
    "        elif (siren_model == \"RELUPE\"):\n",
    "            siren = PosEncMLP(\n",
    "                in_features=2, \n",
    "                out_features=channel_tensor.size()[0], \n",
    "                hidden_features=256,\n",
    "                hidden_layers=3, \n",
    "                num_encoding_freqs=15, \n",
    "                include_input=True, \n",
    "                outermost_linear=True\n",
    "            )\n",
    "        elif (siren_model == \"RELU\"):\n",
    "            siren = PosEncMLP(\n",
    "                in_features=2, \n",
    "                out_features=channel_tensor.size()[0], \n",
    "                hidden_features=256,\n",
    "                hidden_layers=3, \n",
    "                num_encoding_freqs=0, \n",
    "                include_input=True, \n",
    "                outermost_linear=True\n",
    "            )\n",
    "        siren.cuda() # comment this out if testing locally\n",
    "        optim = torch.optim.Adam(lr=lr, params=siren.parameters())\n",
    "        \n",
    "        original_pixels = target_image.pixels.view(width, height).numpy()\n",
    "        \n",
    "        model_input, ground_truth = next(iter(dataloader))\n",
    "        model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "        pbar = tqdm(range(train_steps))\n",
    "        for step in pbar:\n",
    "            output, coords = siren(model_input)\n",
    "            loss = mseloss(output, ground_truth)\n",
    "            # losses.append(loss.detach())\n",
    "            pbar.set_description(\n",
    "                f\"Step {step+1}/{train_steps}. Total loss = {loss}\")\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            full_output, _ = siren(target_image.coords.cuda())\n",
    "            full_output = full_output.cpu().view(width, height).detach().numpy()\n",
    "\n",
    "            inpainted_image = original_pixels.copy()\n",
    "            inpainted_image[~target_image.mask.view(width, height).numpy()] = full_output[~target_image.mask.view(width, height).numpy()]\n",
    "\n",
    "            # clip \n",
    "            predpix = np.clip((inpainted_image + 1) / 2, 0, 1)\n",
    "            ogpix = np.clip((original_pixels + 1) / 2, 0, 1)\n",
    "            \n",
    "            # mse00, psnr00, ssim00 = compute_metrics(ogpix, predpix)\n",
    "            # mses.append(mse00)\n",
    "            # psnrs.append(psnr00)\n",
    "            # ssims.append(ssim00)\n",
    "            reconstructed.append(predpix)\n",
    "            gt.append(ogpix)\n",
    "    return reconstructed, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, num_channels=3, mask_p=1/3, create_mask=True, band_selection=None):\n",
    "    \"\"\"\n",
    "    Given an image produce a mask and an image shape\n",
    "    \"\"\"\n",
    "    image_transposed = np.transpose(img, (2, 0, 1))\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    # if a selection is not provided, create one\n",
    "    if (band_selection is None):\n",
    "        selected = np.random.choice(image_transposed.shape[0], num_channels, replace=False)\n",
    "    else:\n",
    "        selected = np.array(band_selection)\n",
    "    \n",
    "    all_masks_np_array = None\n",
    "    # should I create a mask, or do I just process images\n",
    "    if (create_mask):\n",
    "        hsmask = generate_hyperspectral_masks(height=h, width=w, num_masks=selected, mask_size_ratio=mask_p)\n",
    "        all_masks = visualize_masks(hsmask, height=h, width=w, vis = True)\n",
    "        all_masks_np_array = np.array(all_masks) # Moves the first axis to the last position\n",
    "        \n",
    "    img_selected = image_transposed[selected, :, :]\n",
    "    img_selected = normalize(img_selected)    \n",
    "    return img_selected, all_masks_np_array\n",
    "\n",
    "def generate_hsi_masks(datacube, number_masks=10, randomized=False):\n",
    "    \"\"\"\n",
    "    Given a datacube with defined dimensions (W, H, C), select a fixed number of hyperspectral masks\n",
    "    \"\"\"    \n",
    "    # do I select a uniform selection of bands, or a random set?\n",
    "    if randomized:\n",
    "        band_selection = np.random.choice(datacube.shape[-1], number_masks, replace=False)\n",
    "    else:\n",
    "        band_selection = np.linspace(0, datacube.shape[-1]-1, number_masks, dtype=int)\n",
    "    # select relevant bands\n",
    "    data_selection = datacube[:, :, band_selection]\n",
    "    \n",
    "    _, hyperspectral_masks  = prepare_img(data_selection, num_channels=number_masks, mask_p=1./number_masks)\n",
    "    print(f\"selected bands: {band_selection} final data shape: {hyperspectral_masks.shape}\")\n",
    "    return band_selection, hyperspectral_masks, data_selection \n",
    "\n",
    "def compute_dataset_statistics(datacube, dataset_name, number_masks=10, train_steps=2501):\n",
    "    # don't use this mask.\n",
    "    # selected - bands used\n",
    "    bands_selected, _, data_selection = generate_hsi_masks(datacube, number_masks=number_masks)\n",
    "    selected = np.array([i for i in range(number_masks)]) # use this for the actual bands selected\n",
    "    \"\"\"\n",
    "    Run the training loop to generate statistics\n",
    "    \"\"\"\n",
    "    save_data = {f\"{dataset_name}\": {}}\n",
    "    MSE_stat, PSNR_stat, SSIM_stat = ([], [], [])\n",
    "    for i in range(3, number_masks+1):\n",
    "        # load each image\n",
    "        dtemp = np.array(data_selection[..., :i])\n",
    "        # prepare each image\n",
    "        img_selected, hsi_masks = prepare_img(dtemp, mask_p=1./i, band_selection=selected[:i], create_mask=True)\n",
    "        print(f\"{i}/{number_masks}\")\n",
    "        i += 1\n",
    "        recon, gt = (None, None)\n",
    "        recon, gt = fit_image(img_selected, hsi_masks, train_steps=train_steps)\n",
    "        full_recon = np.transpose(np.array(recon), (1, 2, 0))\n",
    "        full_ground = np.transpose(np.array(gt), (1, 2, 0))\n",
    "        \n",
    "        mse2, psnr2, ssim2 = compute_metrics(full_recon, full_ground)\n",
    "        \n",
    "        MSE_stat.append(mse2)\n",
    "        PSNR_stat.append(psnr2)\n",
    "        SSIM_stat.append(ssim2) \n",
    "        # save data to pickle\n",
    "        save_data[dataset_name][f\"{i}\"] = {\n",
    "            \"reconstructions\": full_recon,\n",
    "            \"ground_truth\": full_ground,\n",
    "            \"bands\": bands_selected,\n",
    "            \"masks\": hsi_masks\n",
    "        }\n",
    "            \n",
    "        if (i == number_masks):\n",
    "            # generate hyperspectral videos\n",
    "            create_hyperspectral_video(full_recon, dataset_name + '_reconstruction.mp4')\n",
    "            create_hyperspectral_video(full_ground, dataset_name + '_truth.mp4')\n",
    "    with open(f'{dataset_name}_checkpoint.pickle', 'wb') as file:\n",
    "        pickle.dump(save_data, file)\n",
    "    return MSE_stat, PSNR_stat, SSIM_stat\n",
    "    \n",
    "def create_fig(mse_stat, psnr_stat, ssim_stat, name):\n",
    "    plt.figure()\n",
    "    X = [i for i in range(3, 11)]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Plot on the left y-axis\n",
    "#     ax1.plot(X[2:], mse_stat[2:], 'b-', label=\"MSE\") # forget about display MSE\n",
    "    ax1.plot(X[2:], ssim_stat[2:], 'b-', label=\"SSIM\")\n",
    "    ax1.set_xlabel(\"Number of Channels\")\n",
    "    ax1.set_ylabel(\"Squared\", color='b')\n",
    "    \n",
    "    # Create a twin axis for the right side\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(X[2:], psnr_stat[2:], 'r--', label=\"PSNR\")\n",
    "    ax2.set_ylabel(\"PSNR (dB)\", color='r')\n",
    "    \n",
    "    # Adding legends\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.title(f\"{name} Reconstruction Performance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## PaviaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(data, 'pavia_u_relu', train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fig(mse_stat, psnr_stat, ssim_stat, 'PaviaUReLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = '/home/bigkeenus/Desktop/JASON/Datasets/CZ_hsdb'\n",
    "real_dir = os.listdir(real_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = loadmat(os.path.join(real_path, real_dir[2]))['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate masks\n",
    "num_masks = 10\n",
    "\n",
    "band_selection = np.random.choice(real_image.shape[-1], num_masks, replace=False)\n",
    "data_selection = real_image[:, :, band_selection]\n",
    "band_selection = np.array([i for i in range(10)])\n",
    "_, hyperspectral_masks  = prepare_img(data_selection, num_channels=num_masks)\n",
    "print(f\"bands: {data_selection.shape} final data shape: {hyperspectral_masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_selection[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(data_selection, 'CZ_hsdb_relu', train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fig(mse_stat, psnr_stat, ssim_stat, 'CZ_hsdbReLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Skin Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "skin_cancer_path = '/home/bigkeenus/Desktop/JASON/Datasets/PaperData/PD1C1/Image.bin'\n",
    "skin_cancer_image = np.fromfile(skin_cancer_path, dtype=np.float32)\n",
    "skin_cancer_cube = skin_cancer_image.reshape(100, 1000, 1000)\n",
    "skin_cancer_cube = np.transpose(skin_cancer_cube, [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skin_cancer_cube[..., 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(skin_cancer_cube, 'dermatology_relu', train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fig(mse_stat, psnr_stat, ssim_stat, 'Dermatology')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## HS-SOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "hssod_path = '/home/bigkeenus/Desktop/JASON/Datasets/HS-SOD/hyperspectral/0006.mat'\n",
    "with h5py.File(hssod_path, 'r') as f:\n",
    "    hssod_image = np.array(f['hypercube'])\n",
    "    hssod_image = np.transpose(hssod_image, [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hssod_image[..., 80])\n",
    "print(hssod_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(hssod_image, 'HS-SOD_relu', train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fig(mse_stat, psnr_stat, ssim_stat, 'HS-SODReLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "\n",
    "folder_selection = 5\n",
    "subimage_selection = 3\n",
    "\n",
    "crops_path = '/home/bigkeenus/Desktop/JASON/Datasets/hyspecnet-11k/patches'\n",
    "patches = os.listdir(crops_path)\n",
    "subpatch_path = os.path.join(crops_path, patches[folder_selection])\n",
    "subpatches = os.listdir(subpatch_path)\n",
    "image_directory = os.path.join(subpatch_path, subpatches[subimage_selection])\n",
    "image_bands = os.listdir(image_directory)\n",
    "##\n",
    "target_image = None\n",
    "for t in image_bands:\n",
    "    if ('SPECTRAL_IMAGE' in t):\n",
    "        target_image = tiff.imread(os.path.join(image_directory, t))\n",
    "        break\n",
    "target_image = np.transpose(target_image, [1, 2, 0])\n",
    "print(f\"Final selected image shape {target_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target_image[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(target_image, 'HySpecNet-11K_relu', train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fig(mse_stat, psnr_stat, ssim_stat, 'HySpecNet-11KReLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Kodak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kodak(m):\n",
    "    kodak_path = '/home/bigkeenus/Desktop/JASON/Datasets/archive/'\n",
    "    kodak_img = os.listdir(kodak_path)\n",
    "    img = cv2.imread(os.path.join(kodak_path, kodak_img[m]))\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kodak1 = read_kodak(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(kodak1, 'KODAK1ReLU', number_masks=3, train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "kodak2 = read_kodak(2)\n",
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(kodak2, 'KODAK2ReLU', number_masks=3, train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "kodak3 = read_kodak(4)\n",
    "plt.imshow(kodak3)\n",
    "mse_stat, psnr_stat, ssim_stat = compute_dataset_statistics(kodak3, 'KODAK3ReLU', number_masks=3, train_steps=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hyperspectral)",
   "language": "python",
   "name": "hyperspectral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
